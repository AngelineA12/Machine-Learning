# -*- coding: utf-8 -*-
"""2348409_Lab7&8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UNoY9BQkD7MJ4S5g6QGjn59EtEhWcQR9

**Linear Discriminant Analysis (LDA) and Logistic Regression**

***LAB 7 and 8***
* *Created by: Angeline A*
* *Reg No: 2348409*
* *3-MDS 'B'*
* Submitted on: 05/04/2024

In the below code, we are importing pandas library which is used to do data manipulation and analysis.
"""

import pandas as pd

"""In the below code, we are importing the data and storing it in a variable named dataframe."""

df = pd.read_csv('/content/data.csv')
df

""" The below code snippet provides a concise summary of the dataset, including the number of samples, number of features, and data types of each column. It's useful for getting a quick understanding of the dataset's structure and characteristics."""

# Display basic information about the dataset
print("Basic information about the dataset:")
print("-----------------------------------")
print("Number of samples:", df.shape[0])  # Number of rows, each row represents a sample
print("Number of features:", df.shape[1] - 2)  # Number of columns, excluding 'diagnosis' and 'id' columns
print("Data types:")
print(df.dtypes)

"""* The above output provides basic information about the Breast Cancer Dataset:

  * Number of samples: There are 569 samples (rows) in the dataset. Each sample represents a patient or observation.

  * Number of features: There are 30 features (columns) in the dataset. These features represent various measurements and characteristics of breast cancer tumors, such as radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, and fractal dimension.

  * Data types: The 'id' column is of type int64, and the 'diagnosis' column is of type object. The 'diagnosis' column likely contains categorical data with two categories ('M' for malignant and 'B' for benign). The remaining columns (radius_mean to fractal_dimension_worst) are of type float64, indicating they contain numerical data representing tumor characteristics.

In the below code, we are printing the first five rows of the dataset to understand the data.
"""

# Display the first few rows
print("First few rows of the dataset:")
print("-----------------------------------")
df.head()

"""In the below code we are importing the necessary libraries for visualizations."""

import matplotlib.pyplot as plt
import seaborn as sns

"""In the below code, we are generating a violin plot to understand the distribution of the dataset."""

# Box plot for selected features
selected_features = ['concave_points_mean', 'concavity_mean', 'compactness_mean',
                     'smoothness_mean', 'area_mean', 'perimeter_mean',
                     'texture_mean', 'radius_mean']
# Violin plot for selected features
plt.figure(figsize=(14, 8))
sns.violinplot(data=df[selected_features], palette='pastel')
plt.title('Violin plot of Selected Features')
plt.xticks(rotation=45)
plt.show()

"""From the above graph we can infer the following,
* In this specific violin plot, the features on the x-axis are “concave points mean”, “concavity mean”, “compactness mean”, “smoothness mean”, “area mean”, “perimeter mean”, “texture mean”, and “radius mean”. The y-axis shows the number of features.

* It appears that the data for most features is clustered around the median, with a few outliers on either side.

The below code generate a box plot which is a useful visualization for understanding the distribution, spread, and potential outliers within each selected feature in the dataset.
"""

plt.figure(figsize=(14, 8))
sns.boxplot(data=df[selected_features], palette='pastel')
plt.title('Boxplot of Selected Features')
plt.xticks(rotation=45)
plt.show()

"""The below code generates the pair plot that allows for the visualization of pairwise relationships between the selected numeric features and the diagnosis column, providing insights into the distribution and relationships of these variables."""

# Convert 'diagnosis' column to integer values
df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})

# Selecting the numeric features for pair plot
selected_features = ['concave_points_mean', 'concavity_mean', 'compactness_mean',
                     'smoothness_mean', 'area_mean', 'perimeter_mean',
                     'texture_mean', 'radius_mean']

# Adding 'diagnosis' to selected features for hue
selected_features_with_diagnosis = selected_features + ['diagnosis']

# Set the style for seaborn
sns.set(style="ticks", color_codes=True)

# Create pair plot
sns.pairplot(df[selected_features_with_diagnosis], hue='diagnosis', palette='husl', diag_kind='kde')
plt.show()

"""From the above we can infer many information, the few information are mentioned below,
* Observation 1: The data points show a positive diagonal cluster. This suggests a positive correlation, where higher values in "concave_points_mean" tend to be accompanied by higher values in "concavity_mean".
* Observation 2: The KDE plots for both diagnoses on the diagonal show some overlap but also a slight separation. This might indicate a generally similar distribution of values for both diagnoses, but with a possibility of some "concavity_mean" values being higher for diagnosis 1 compared to diagnosis 0.

The below code provides a summary of basic descriptive statistics for the numerical columns in the dataset, offering insights into the central tendency, variability, and distribution of the data.
"""

# Select numerical columns for analysis (excluding 'diagnosis' and 'id')
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns

# Calculate basic descriptive statistics
basic_stats = df[numerical_cols].describe().transpose()

# Display basic descriptive statistics
print("Basic Descriptive Statistics:")
print(basic_stats)

"""From the above result, we can observe the following for each of the columns,
* id:
  * This column represents unique identifiers for each observation.
  * It has a count of 569, indicating that there are no missing values.
  * The minimum ID is 8670, and the maximum ID is 9113205.

* diagnosis:
  * This column contains categorical values indicating the diagnosis of tumors ('M' for malignant and 'B' for benign).
  * The count is 569, indicating no missing values.
  * The mean is approximately 0.372, suggesting that about 37.2% of tumors are malignant on average.

* radius_mean:
  * This column represents the mean radius of tumors.
  * The mean radius is approximately 14.13 units, with a standard deviation of approximately 3.52 units.
  * The minimum radius is 6.98 units, and the maximum radius is 28.11 units.

* texture_mean:
  * The mean texture of tumors is approximately 19.29 units, with a standard deviation of approximately 4.30 units.
  * The minimum texture is 9.71 units, and the maximum texture is 39.28 units.

* perimeter_mean:
 *  The mean perimeter of tumors is approximately 91.97 units, with a standard deviation of approximately 24.30 units.
 * The minimum perimeter is 43.79 units, and the maximum perimeter is 188.50 units.

* area_mean:
  * The mean area of tumors is approximately 654.89 square units, with a standard deviation of approximately 351.91 square units.
  * The minimum area is 143.50 square units, and the maximum area is 2501.00 square units.

* smoothness_mean:
  * The mean smoothness of tumors is approximately 0.096, with a standard deviation of approximately 0.014.
  * The minimum smoothness is 0.05263, and the maximum smoothness is 0.1634.

* compactness_mean:
  * The mean compactness of tumors is approximately 0.104, with a standard deviation of approximately 0.053.
  * The minimum compactness is 0.01938, and the maximum compactness is 0.3454.

* concavity_mean:
  * The mean concavity of tumors is approximately 0.089, with a standard deviation of approximately 0.080.
  * The minimum concavity is 0, and the maximum concavity is 0.4268.

* concave_points_mean:
  * The mean number of concave points of tumors is approximately 0.049, with a standard deviation of approximately 0.039.
  * The minimum number of concave points is 0, and the maximum number of concave points is 0.2012.

The below code efficiently creates paired histograms and box plots for each numerical column, allowing for visual inspection of the distribution and variability of each feature in the dataset.
"""

# Visualize the distribution using histograms and box plots
for col in numerical_cols:
    plt.figure(figsize=(10, 5))

    # Histogram
    plt.subplot(1, 2, 1)
    sns.histplot(data=df, x=col, kde=True)
    plt.title(f'Histogram of {col}')

    # Box plot
    plt.subplot(1, 2, 2)
    sns.boxplot(data=df, y=col)
    plt.title(f'Box plot of {col}')

    plt.tight_layout()
    plt.show()

"""From the above graphical representations, we can infer that almost all the numerical values are normally distributed except for few and the all the column has outliers.

In the below code, we are seperating the categorical variable. and storing it in a variable.
"""

# Select categorical columns for analysis (assuming 'diagnosis' column is categorical)
categorical_cols = ['diagnosis']

"""The below code effectively generates both frequency tables and bar plots for each categorical column, allowing for a visual and quantitative understanding of the distribution of categories within the dataset.

"""

# Display frequency tables showing counts and percentages
for col in categorical_cols:
    frequency_table = df[col].value_counts(normalize=True) * 100
    print(f"Frequency table for {col}:")
    print(frequency_table)
    print("\n")

    # Visualize using bar plots
    plt.figure(figsize=(8, 5))
    sns.countplot(data=df, x=col)
    plt.title(f'Bar plot of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.show()

"""* The provided frequency table is for the 'diagnosis' column, which contains categorical values indicating the diagnosis of tumors. Here's an explanation of the result:

  * diagnosis: This column represents the diagnosis of tumors, with '0' indicating benign tumors and '1' indicating malignant tumors.
* The frequency table shows the proportion of each diagnosis category within the column:

  * Category '0' (benign tumors) accounts for approximately 62.74% of the diagnoses.
  * Category '1' (malignant tumors) accounts for approximately 37.26% of the diagnoses.
* This indicates that in the dataset:

  * Around 62.74% of tumors are diagnosed as benign.
  * Around 37.26% of tumors are diagnosed as malignant.
* These percentages provide insights into the distribution of diagnoses within the dataset, indicating the relative prevalence of benign and malignant tumors.

* From the graph we can infer that the count of malignant is high than Benign which means the no of people in serious condition is less compared to the people in initial stage of cancer.

In the below code, we seperating the numerical variables and categorical variables and storing it in a variable.
"""

# Bivariate analysis between numerical and categorical variables using box plots or violin plots
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = ['diagnosis']

"""The below code allows for visual examination of how the distribution of numerical variables varies across different categories of categorical variables, providing insights into potential relationships or differences within the dataset."""

for num_col in numerical_cols:
    for cat_col in categorical_cols:
        plt.figure(figsize=(8, 6))
        sns.boxplot(data=df, x=cat_col, y=num_col)
        plt.title(f'{cat_col} vs {num_col}')
        plt.xlabel(cat_col)
        plt.ylabel(num_col)
        plt.show()

"""From the above graph, we can see how the affected rate is ditributed and for each of the columns which means we can observe that the how the level of each of the columns are for the two categories of the diseases and how they are distributed.

In the below code, we are removing the unwanted column id which is not necessary for the further analysis.
"""

# Drop non-required columns ('id' column)
df.drop(columns=['id'], inplace=True)

"""In the below code, we are seperating the independent and dependent variables and storing it in variables X and Y."""

# Separate the features (X) and the target variable (y)
X = df.drop(columns=['diagnosis'])  # Features
y = df['diagnosis']  # Target variable

"""In the below code, we are importing the necessary library for standardizing the variables."""

from sklearn.preprocessing import StandardScaler

"""In the below cide, we are standardizing the X (independent variable)."""

# Perform standardization on the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""In the below code, we are importing the necessary library to split the dataset for training and testing."""

from sklearn.model_selection import train_test_split

"""In the below code, we are spliting the dataset for training and testing (both independent and dependent) and storing them in the variable."""

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""In the below code, we are imprting the necessary packkages to perform LDA and logistic regression and futher analysis."""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""In the below code, we are training the model using taring data for LDA"""

# 11. Implement Linear Discriminant Analysis (LDA)
# a. Train the LDA model using training data
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)

"""In the below code, we are evealuating the performance of the trained model by predicting the values for trained independent variable and untarined independent varibale which basically the independent variable from the training dataset and the testing dataset."""

# b. Evaluate the performance of the trained model using appropriate metrics
lda_train_preds = lda.predict(X_train)
lda_test_preds = lda.predict(X_test)

"""In the below code, we are checking the accuracy score of the model both for trained dataset and the testing dataset."""

lda_train_accuracy = accuracy_score(y_train, lda_train_preds)
lda_test_accuracy = accuracy_score(y_test, lda_test_preds)

"""In the below code, we printing the accuracy score of the model for both the training and the testing dataset."""

print("Linear Discriminant Analysis (LDA) Model Performance:")
print("Train Accuracy:", lda_train_accuracy)
print("Test Accuracy:", lda_test_accuracy)

"""From the above result we can infer that the,
* Accuracy score of model for Training Dataset is 96.5%
* Accuracy score of model for Testing Dataset is 95.6%

In the below code, we building the Logistic regression model and we are training the model with training dataset.
"""

# 12. Implement Logistic Regression
# a. Train the Logistic Regression model using the training data
logreg = LogisticRegression(max_iter=1000)  # Increase max_iter if convergence warnings occur
logreg.fit(X_train, y_train)

"""In the below code, we are evaluating the performance of the trained model both for trained dataset and the testing dataset."""

# b. Evaluate the performance of the trained model using appropriate metrics
logreg_train_preds = logreg.predict(X_train)
logreg_test_preds = logreg.predict(X_test)

"""In the below code, we are getting the accuracy score for the model for both trained dataset and the testing dataset."""

logreg_train_accuracy = accuracy_score(y_train, logreg_train_preds)
logreg_test_accuracy = accuracy_score(y_test, logreg_test_preds)

"""In the below code, we are printing the Accuracy score for the LR model for both training and testing dataset."""

print("\nLogistic Regression Model Performance:")
print("Train Accuracy:", logreg_train_accuracy)
print("Test Accuracy:", logreg_test_accuracy)

"""From the above result, we can observe that the the,
* Accurcay score of model for training dataset is 98.6%
* Accuracy score of model for testing dataset is 97.4%

The below code allows for a concise summary of the performance of the LDA model in terms of precision, recall, and the confusion matrix, which helps in evaluating the model's effectiveness in predicting the target variable.
"""

# 13. Display the classification report and confusion matrix
print("\nClassification Report and Confusion Matrix for Linear Discriminant Analysis:")
print(classification_report(y_test, lda_test_preds))
print("Confusion Matrix:")
print(confusion_matrix(y_test, lda_test_preds))

"""The provided output includes the classification report and confusion matrix for the results of a Linear Discriminant Analysis (LDA) model.

* Classification Report:

  * The classification report provides a summary of performance metrics such as precision, recall, F1-score, and support for each class (in this case, classes 0 and 1).
    * For class 0 (presumably representing benign tumors):
      * Precision: 0.95 (i.e., when the model predicts a tumor as benign, it is correct about 95% of the time)
      * Recall: 0.99 (i.e., the model correctly identifies about 99% of actual benign tumors)
      * F1-score: 0.97 (the harmonic mean of precision and recall, providing a balance between them)
      * Support: 71 (the number of samples in the test set with actual class 0)
    * For class 1 (presumably representing malignant tumors):
      * Precision: 0.97 (i.e., when the model predicts a tumor as malignant, it is correct about 97% of the time)
      * Recall: 0.91 (i.e., the model correctly identifies about 91% of actual malignant tumors)
      * F1-score: 0.94
      * Support: 43 (the number of samples in the test set with actual class 1)
      * Accuracy: 0.96 (overall accuracy of the model in predicting both classes)

Macro average and weighted average metrics provide an average of precision, recall, and F1-score across all classes, considering class imbalance.
Confusion Matrix:

* The confusion matrix summarizes the performance of the classification model by showing the count of true positive, true negative, false positive, and false negative predictions.

In the confusion matrix:
* The top-left cell (70) represents true negatives (TN) - the number of correctly predicted benign tumors.
* The top-right cell (1) represents false positives (FP) - the number of benign tumors incorrectly predicted as malignant.
* The bottom-left cell (4) represents false negatives (FN) - the number of malignant tumors incorrectly predicted as benign.
* The bottom-right cell (39) represents true positives (TP) - the number of correctly predicted malignant tumors.

This information provides insights into the model's performance, indicating its ability to correctly classify tumors as benign or malignant, as well as any potential errors in prediction.

The below code allows for the evaluation of the Logistic Regression model's performance in terms of precision, recall, F1-score, and confusion matrix, providing insights into its effectiveness in predicting the target variable.
"""

print("\nClassification Report and Confusion Matrix for Logistic Regression:")
print(classification_report(y_test, logreg_test_preds))
print("Confusion Matrix:")
print(confusion_matrix(y_test, logreg_test_preds))

"""The provided output includes the classification report and confusion matrix for the results of a Logistic Regression model.

* Classification Report:

  * Precision:
    * For class 0 (presumably representing benign tumors), precision is 0.97, indicating that when the model predicts a tumor as benign, it is correct about 97% of the time.
    * For class 1 (presumably representing malignant tumors), precision is 0.98, meaning that when the model predicts a tumor as malignant, it is correct about 98% of the time.
  * Recall:
    * For class 0, recall is 0.99, suggesting that the model correctly identifies about 99% of actual benign tumors.
    * For class 1, recall is 0.95, indicating that the model correctly identifies about 95% of actual malignant tumors.
  * F1-score:
    * The harmonic mean of precision and recall.
    * For class 0, it is 0.98.
    * For class 1, it is 0.96.
  * Support:
    * The number of samples in the test set with actual class 0 is 71, and for class 1, it is 43.
  * Accuracy: Overall accuracy of the model in predicting both classes is 0.97.
* Confusion Matrix:

  * The confusion matrix summarizes the performance of the classification model by showing the count of true positive, true negative, false positive, and false negative predictions.
  * In the confusion matrix, the top-left cell (70) represents true negatives (TN) - the number of correctly predicted benign tumors.
  * The top-right cell (1) represents false positives (FP) - the number of benign tumors incorrectly predicted as malignant.
  * The bottom-left cell (2) represents false negatives (FN) - the number of malignant tumors incorrectly predicted as benign.
  * The bottom-right cell (41) represents true positives (TP) - the number of correctly predicted malignant tumors.

The below code allows for the visualization and comparison of the confusion matrices, providing insights into the performance of the classification models in predicting the target variable.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Plot confusion matrices for both LDA and Logistic Regression models
plt.figure(figsize=(12, 6))

# Confusion matrix for LDA
plt.subplot(1, 2, 1)
lda_cm = confusion_matrix(y_test, lda_test_preds)
sns.heatmap(lda_cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix - LDA')
plt.xlabel('Predicted')
plt.ylabel('Actual')

# Confusion matrix for Logistic Regression
plt.subplot(1, 2, 2)
logreg_cm = confusion_matrix(y_test, logreg_test_preds)
sns.heatmap(logreg_cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')

plt.tight_layout()
plt.show()

"""Insights from the graph:

* Both models perform similarly in correctly predicting class 0, with 70 TN each.
* Logistic Regression performs slightly better in predicting class 1, with 41 TP compared to LDA's 39 TP.
* Logistic Regression also has fewer FN, with only 2 compared to LDA's 4, indicating it is better at identifying class 1 instances.
* Both models have a low FP rate, with only 1 FP each, indicating that they both are good at not misclassifying class 0 instances as class 1.

Overall, the Logistic Regression model appears to have a slight edge over the LDA model in terms of overall accuracy and precision in this particular dataset.

The below code allows for a visual comparison of the accuracies of the two models, providing insights into their relative performance.
"""

# Compare accuracies of both models using a bar plot
models = ['LDA', 'Logistic Regression']
accuracies = [lda_test_accuracy, logreg_test_accuracy]

plt.figure(figsize=(8, 5))
sns.barplot(x=models, y=accuracies, palette='Blues')
plt.title('Comparison of Model Accuracies')
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.ylim(0, 1)  # Set y-axis limit to ensure visibility of differences
plt.show()

"""The image displays a bar chart comparing the accuracies of two classification models:
* Linear Discriminant Analysis (LDA) and Logistic Regression.
* Both bars are quite high, indicating that both models perform well on the dataset they were tested on.
* However, the bar for Logistic Regression is slightly higher than the one for LDA, suggesting that Logistic Regression has a higher accuracy in this particular comparison.
"""